{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('breast_cancer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing redundant information\n",
    "dataset.drop(['Unnamed: 32',\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to put diagnosis in a numerical form for the model\n",
    "dataset.diagnosis = [1 if each == \"M\" else 0 for each in dataset.diagnosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the x and y variables\n",
    "y = dataset.diagnosis.values\n",
    "x_data = dataset.drop(['diagnosis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the data since features have different scales for their values\n",
    "x = (x_data -np.min(x_data))/(np.max(x_data)-np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (30, 483)\n",
      "x test:  (30, 86)\n",
      "y train:  (483,)\n",
      "y test:  (86,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "print(\"x train: \", x_train.shape)\n",
    "print(\"x test: \", x_test.shape)\n",
    "print(\"y train: \", y_train.shape)\n",
    "print(\"y test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising some parameters needed\n",
    "# What we need is dimension 4096 that is the number of pixels as a parameter for our initialize method(def)\n",
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b = 0.0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of z for the logistic regression\n",
    "# z = np.dot(w.T,x_train) + b\n",
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In backward propagation we will use the y_head that was found in forward progation\n",
    "# Therefore instead of writing backward propagation method, let's combine forward propagation and backward propagation\n",
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    # forward propagation\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update our parameters by learning better ones\n",
    "\n",
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    # updating(learning) parameters is number_of_iterarion times\n",
    "    for i in range(number_of_iterarion):\n",
    "        # make forward and backward propagation and find cost and gradients\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        # lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    # we update(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction shows 1 (y_head = 1)\n",
    "    # if z is smaller than 0.5, our prediction shows 0 (y_head = 0)\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692836\n",
      "Cost after iteration 10: 0.498576\n",
      "Cost after iteration 20: 0.404996\n",
      "Cost after iteration 30: 0.350059\n",
      "Cost after iteration 40: 0.313747\n",
      "Cost after iteration 50: 0.287767\n",
      "Cost after iteration 60: 0.268114\n",
      "Cost after iteration 70: 0.252627\n",
      "Cost after iteration 80: 0.240036\n",
      "Cost after iteration 90: 0.229543\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 94.40993788819875 %\n",
      "test accuracy: 94.18604651162791 %\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    # initialize\n",
    "    dimension =  x_train.shape[0]  # that is 4096\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    # do not change the learning rate!\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate, num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "   \n",
    "    \n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9651162790697675 \n",
      "train accuracy: 0.9668737060041408 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# We can compare this with the sklearn implementation of the logistic regression model and see it comes pretty close to ours\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression(random_state = 42,max_iter= 150)\n",
    "\n",
    "print(\"test accuracy: {} \".format(logreg.fit(x_train.T, y_train.T).score(x_test.T, y_test.T)))\n",
    "print(\"train accuracy: {} \".format(logreg.fit(x_train.T, y_train.T).score(x_train.T, y_train.T)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
